{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ericpts/.local/lib/python3.8/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import concurrent.futures\n",
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable, Dict, List, Optional\n",
    "\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import gin\n",
    "import lib_analysis\n",
    "import lib_biased_mnist\n",
    "import lib_plot\n",
    "import lib_problem\n",
    "import lib_toy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import yaml\n",
    "from jupyter_dash import JupyterDash\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "external_stylesheets = [\"https://codepen.io/chriddyp/pen/bWLwgP.css\"]\n",
    "\n",
    "tqdm.pandas()\n",
    "gin.enter_interactive_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df(data_root: Path, experiment_name: str) -> pd.DataFrame:\n",
    "    df_path = data_root / experiment_name / \"df.pickle\"\n",
    "    if df_path.exists():\n",
    "        print(f\"Found cached df at {df_path}. Reusing...\", flush=True)\n",
    "        return pd.read_pickle(str(df_path))\n",
    "\n",
    "    DF = lib_analysis.read_problem(data_root, experiment_name)\n",
    "    DF = lib_analysis.add_statistics_to_df(DF)\n",
    "\n",
    "    DF.to_pickle(str(df_path), protocol=4)\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found cached df at ../data/biased_mnist_10_digits/df.pickle. Reusing...\n"
     ]
    }
   ],
   "source": [
    "data_root = Path(\"../data/\")\n",
    "DF = read_df(data_root, \"biased_mnist_10_digits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_prediction_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_diversity_loss</th>\n",
       "      <th>test_combined_loss</th>\n",
       "      <th>test_ensemble_accuracy</th>\n",
       "      <th>train_prediction_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_diversity_loss</th>\n",
       "      <th>train_combined_loss</th>\n",
       "      <th>train_ensemble_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>Problem.initial_lr</th>\n",
       "      <th>Problem.decrease_lr_at_epochs</th>\n",
       "      <th>Problem.n_models</th>\n",
       "      <th>get_weight_regularizer.strength</th>\n",
       "      <th>yaml_config_file</th>\n",
       "      <th>gin_config_file</th>\n",
       "      <th>ood_statistics</th>\n",
       "      <th>id_statistics</th>\n",
       "      <th>ood_disagreement_rate</th>\n",
       "      <th>id_disagreement_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>[22.31837272644043, 11.712209701538086]</td>\n",
       "      <td>[0.09960000216960907, 0.25619998574256897]</td>\n",
       "      <td>0.196011</td>\n",
       "      <td>37.166756</td>\n",
       "      <td>0.1607</td>\n",
       "      <td>[0.030147647485136986, 0.0073644788935780525]</td>\n",
       "      <td>[0.9989500045776367, 0.9991000294685364]</td>\n",
       "      <td>0.185107</td>\n",
       "      <td>2.999228</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[20, 40, 80]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>/home/ericpts/work/data/biased_mnist/cka/mlp/l...</td>\n",
       "      <td>/home/ericpts/work/data/biased_mnist/cka/mlp/l...</td>\n",
       "      <td>{'overall': {'ensemble': {'accuracy': tf.Tenso...</td>\n",
       "      <td>{'overall': {'ensemble': {'accuracy': tf.Tenso...</td>\n",
       "      <td>0.3573</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         test_prediction_loss  \\\n",
       "1697  [22.31837272644043, 11.712209701538086]   \n",
       "\n",
       "                                   test_accuracy  test_diversity_loss  \\\n",
       "1697  [0.09960000216960907, 0.25619998574256897]             0.196011   \n",
       "\n",
       "      test_combined_loss  test_ensemble_accuracy  \\\n",
       "1697           37.166756                  0.1607   \n",
       "\n",
       "                              train_prediction_loss  \\\n",
       "1697  [0.030147647485136986, 0.0073644788935780525]   \n",
       "\n",
       "                                train_accuracy  train_diversity_loss  \\\n",
       "1697  [0.9989500045776367, 0.9991000294685364]              0.185107   \n",
       "\n",
       "      train_combined_loss  train_ensemble_accuracy  ... Problem.initial_lr  \\\n",
       "1697             2.999228                   0.9991  ...               0.01   \n",
       "\n",
       "     Problem.decrease_lr_at_epochs Problem.n_models  \\\n",
       "1697                  [20, 40, 80]                2   \n",
       "\n",
       "     get_weight_regularizer.strength  \\\n",
       "1697                            0.01   \n",
       "\n",
       "                                       yaml_config_file  \\\n",
       "1697  /home/ericpts/work/data/biased_mnist/cka/mlp/l...   \n",
       "\n",
       "                                        gin_config_file  \\\n",
       "1697  /home/ericpts/work/data/biased_mnist/cka/mlp/l...   \n",
       "\n",
       "                                         ood_statistics  \\\n",
       "1697  {'overall': {'ensemble': {'accuracy': tf.Tenso...   \n",
       "\n",
       "                                          id_statistics  \\\n",
       "1697  {'overall': {'ensemble': {'accuracy': tf.Tenso...   \n",
       "\n",
       "      ood_disagreement_rate  id_disagreement_rate  \n",
       "1697                 0.3573                0.0012  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_column_from_statistics(\n",
    "    df: pd.DataFrame, f_per_row: Callable[[Dict], Dict]\n",
    ") -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df_new = df[[\"id_statistics\", \"ood_statistics\"]].apply(f_per_row, axis=1)\n",
    "\n",
    "    df_new_t = {}\n",
    "    for x in df_new:\n",
    "        for k, v in x.items():\n",
    "            if k not in df_new_t:\n",
    "                df_new_t[k] = []\n",
    "            df_new_t[k].append(v)\n",
    "    df_new_t = pd.DataFrame(df_new_t)\n",
    "    return pd.concat([df.reset_index(drop=True), df_new_t], axis=1)\n",
    "\n",
    "\n",
    "def f_extract_disagreement_per_row(row: Dict) -> pd.Series:\n",
    "    ood_dis = row[\"ood_statistics\"][\"disagreement\"]\n",
    "    ood_disagreement_rate = ood_dis[\"n_select\"].numpy() / ood_dis[\"n_original\"]\n",
    "\n",
    "    id_dis = row[\"id_statistics\"][\"disagreement\"]\n",
    "    if \"n_select\" not in id_dis:\n",
    "        id_disagreement_rate = 0.0\n",
    "    else:\n",
    "        id_disagreement_rate = id_dis[\"n_select\"].numpy() / id_dis[\"n_original\"]\n",
    "\n",
    "    return {\n",
    "        \"ood_disagreement_rate\": ood_disagreement_rate,\n",
    "        \"id_disagreement_rate\": id_disagreement_rate,\n",
    "    }\n",
    "\n",
    "\n",
    "add_column_from_statistics(DF, f_extract_disagreement_per_row).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics_for_series(row: pd.Series):\n",
    "    return [\n",
    "        html.Div(\n",
    "            [\n",
    "                html.H4(\"Out of Distribution\"),\n",
    "                *lib_analysis.format_statistics(row[\"ood_statistics\"]),\n",
    "            ]\n",
    "        ),\n",
    "        html.Div(\n",
    "            [\n",
    "                html.H4(\"In Distribution\"),\n",
    "                *lib_analysis.format_statistics(row[\"id_statistics\"]),\n",
    "            ]\n",
    "        ),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for lr 0.0001\n",
      "Processing data for lr 0.001\n",
      "Processing data for lr 0.01\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fd74e72ef40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_level_tabs = []\n",
    "\n",
    "indep = \"cka\"\n",
    "\n",
    "for lr in np.unique(DF[\"Problem.initial_lr\"])[:3]:\n",
    "    print(f\"Processing data for lr {lr}\")\n",
    "    tabs_for_outer = []\n",
    "    for l_corr in np.unique(DF[\"label_correlation\"]):\n",
    "\n",
    "        def stats_for_lambda(lambda_: float):\n",
    "            df = (\n",
    "                DF[\n",
    "                    (DF[\"label_correlation\"] == l_corr)\n",
    "                    & (DF[\"indep\"] == indep)\n",
    "                    & (DF[\"lambda\"] == lambda_)\n",
    "                    & (DF[\"Problem.initial_lr\"] == lr)\n",
    "                ]\n",
    "                .sample(1)\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "            return statistics_for_series(df.iloc[0])\n",
    "\n",
    "        df_for_fig = DF[\n",
    "            (DF[\"label_correlation\"] == l_corr) & (DF[\"Problem.initial_lr\"] == lr)\n",
    "        ].copy()\n",
    "\n",
    "        fig_train_diversity = lib_plot.end_to_end_plot(\n",
    "            go.Figure(),\n",
    "            df_for_fig,\n",
    "            \"train_diversity_loss\",\n",
    "            [\"indep\"],\n",
    "            f\"Train diversity loss for label correlation {l_corr}; learning rate {lr}\",\n",
    "        )\n",
    "\n",
    "        fig_id_disagreement = lib_plot.end_to_end_plot(\n",
    "            go.Figure(),\n",
    "            add_column_from_statistics(df_for_fig, f_extract_disagreement_per_row),\n",
    "            \"id_disagreement_rate\",\n",
    "            [\"indep\"],\n",
    "            f\"ID Disagreement rate for label correlation {l_corr}; learning rate {lr}\",\n",
    "        )\n",
    "\n",
    "        fig_ood_disagreement = lib_plot.end_to_end_plot(\n",
    "            go.Figure(),\n",
    "            add_column_from_statistics(df_for_fig, f_extract_disagreement_per_row),\n",
    "            \"ood_disagreement_rate\",\n",
    "            [\"indep\"],\n",
    "            f\"OOD Disagreement rate for label correlation {l_corr}; learning rate {lr}\",\n",
    "        )\n",
    "\n",
    "        per_lambda_stats = html.Div(\n",
    "            [\n",
    "                dcc.Tabs(\n",
    "                    [\n",
    "                        dcc.Tab(\n",
    "                            label=f\"Lambda = {lambda_}\",\n",
    "                            children=stats_for_lambda(lambda_),\n",
    "                        )\n",
    "                        for lambda_ in np.unique(DF[\"lambda\"])\n",
    "                    ]\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        tabs_for_outer.append(\n",
    "            dcc.Tab(\n",
    "                label=f\"label correlation {l_corr}\",\n",
    "                children=[\n",
    "                    dcc.Graph(figure=fig_train_diversity),\n",
    "                    dcc.Graph(figure=fig_id_disagreement),\n",
    "                    dcc.Graph(figure=fig_ood_disagreement),\n",
    "                    per_lambda_stats,\n",
    "                ],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    top_level_tabs.append(\n",
    "        dcc.Tab(label=f\"learning rate {lr}\", children=[dcc.Tabs(tabs_for_outer)],)\n",
    "    )\n",
    "\n",
    "app = JupyterDash(__name__, external_stylesheets=external_stylesheets)\n",
    "app.layout = html.Div([dcc.Tabs(top_level_tabs)])\n",
    "app.run_server(mode=\"inline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
