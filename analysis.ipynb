{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ericpts/.local/lib/python3.8/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import concurrent.futures\n",
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable, Dict, List, Optional\n",
    "\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import gin\n",
    "import lib_analysis\n",
    "import lib_biased_mnist\n",
    "import lib_plot\n",
    "import lib_problem\n",
    "import lib_toy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import yaml\n",
    "from jupyter_dash import JupyterDash\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "external_stylesheets = [\"https://codepen.io/chriddyp/pen/bWLwgP.css\"]\n",
    "\n",
    "tqdm.pandas()\n",
    "gin.enter_interactive_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gin.parse_config_file(\"one-off/config.gin\")\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "problem = lib_biased_mnist.BiasedMnistProblem()\n",
    "\n",
    "in_dist = tf.data.Dataset.from_tensor_slices(\n",
    "    problem.filter_tensors(\n",
    "        *lib_biased_mnist.get_biased_mnist_data(\"~/.datasets/mnist/\", 1.0, train=False)\n",
    "    )\n",
    ").cache()\n",
    "\n",
    "oo_dist = tf.data.Dataset.from_tensor_slices(\n",
    "    problem.filter_tensors(\n",
    "        *lib_biased_mnist.get_biased_mnist_data(\"~/.datasets/mnist/\", 0.1, train=False)\n",
    "    )\n",
    ").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_generalization_error(X, y, y_biased, y_hat):\n",
    "    per_digit_accuracy = lib_analysis.make_confusion_matrix(X, y, y_biased, y_hat)\n",
    "    errors = []\n",
    "    for bg in range(10):\n",
    "        per_digit = [None] * 2\n",
    "\n",
    "        for digit in range(2):\n",
    "            n_correct, n_total = per_digit_accuracy[digit, bg]\n",
    "            if n_total == 0:\n",
    "                per_digit[digit] = 0.0\n",
    "            else:\n",
    "                per_digit[digit] = n_correct / n_total\n",
    "\n",
    "        e = (per_digit[0] - per_digit[1]) ** 2.0\n",
    "        errors.append(e)\n",
    "    mse = np.mean(errors)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row: pd.DataFrame, root: Path):\n",
    "    models = []\n",
    "    for p in row[\"model_paths\"]:\n",
    "        p = root / Path(p)\n",
    "        m = tf.keras.models.load_model(p, compile=False)\n",
    "        models.append(m)\n",
    "\n",
    "    batch_size = 1024\n",
    "    # in_X, in_y, in_y_biased, in_y_hat = process_dataset(in_dist, models, batch_size)\n",
    "    oo_X, oo_y, oo_y_biased, oo_y_hat = lib_analysis.process_dataset(\n",
    "        oo_dist, models, batch_size\n",
    "    )\n",
    "\n",
    "    ret = {}\n",
    "    per_network = sorted(\n",
    "        [\n",
    "            model_generalization_error(\n",
    "                oo_X, oo_y, oo_y_biased, tf.math.argmax(oo_y_hat, axis=-1)[:, im]\n",
    "            )\n",
    "            for im in range(2)\n",
    "        ]\n",
    "    )\n",
    "    for im in range(2):\n",
    "        ret[f\"network_{im}_generalization_error\"] = per_network[im]\n",
    "\n",
    "    ret[\"ensemble_generalization_error\"] = model_generalization_error(\n",
    "        oo_X,\n",
    "        oo_y,\n",
    "        oo_y_biased,\n",
    "        tf.math.argmax(tf.math.reduce_mean(oo_y_hat, axis=1), axis=-1),\n",
    "    )\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_generalization_error(df: pd.DataFrame, root: Path) -> pd.DataFrame:\n",
    "    genzation = df.progress_apply(lambda row: process_row(row, root), axis=1)\n",
    "    keys = genzation[0].keys()\n",
    "    d = {k: [] for k in keys}\n",
    "\n",
    "    for g in genzation:\n",
    "        for k in keys:\n",
    "            d[k].append(g[k])\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(d)], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_generalization_rows(row: pd.DataFrame):\n",
    "    df = []\n",
    "    for col in [\"network_0\", \"network_1\", \"ensemble\"]:\n",
    "        row_name = f\"{col}_generalization_error\"\n",
    "        d = row[row_name]\n",
    "        r = row.copy()\n",
    "        r[\"generalization_error\"] = d\n",
    "        r[\"generalization_error_model\"] = col\n",
    "        df.append(r)\n",
    "    df = pd.DataFrame(df)\n",
    "    for col in [\"network_0\", \"network_1\", \"ensemble\"]:\n",
    "        row_name = f\"{col}_generalization_error\"\n",
    "        df = df.drop(row_name, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = Path(\"../data/3c2e4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 720/720 [03:57<00:00,  3.04it/s]\n",
      "100%|██████████| 720/720 [00:06<00:00, 106.59it/s]\n"
     ]
    }
   ],
   "source": [
    "DF = lib_analysis.read_problem(data_root, \"biased_mnist\")\n",
    "DF = add_generalization_error(DF, data_root)\n",
    "DF = pd.concat(list(DF.progress_apply(expand_generalization_rows, axis=1))).reset_index(\n",
    "    drop=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics_for_series(df: pd.Series):\n",
    "    models = []\n",
    "    for p in df[\"model_paths\"]:\n",
    "        p = data_root / Path(p)\n",
    "        m = tf.keras.models.load_model(p, compile=False)\n",
    "        models.append(m)\n",
    "\n",
    "    batch_size = 1024\n",
    "    # in_X, in_y, in_y_biased, in_y_hat = process_dataset(in_dist, models, batch_size)\n",
    "    oo_X, oo_y, oo_y_biased, oo_y_hat = lib_analysis.process_dataset(\n",
    "        oo_dist, models, batch_size\n",
    "    )\n",
    "    return lib_analysis.print_statistics(oo_X, oo_y, oo_y_biased, oo_y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f00d70c69a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_level_tabs = []\n",
    "\n",
    "for lr in np.unique(DF[\"Problem.initial_lr\"]):\n",
    "    tabs_for_outer = []\n",
    "    for l_corr in np.unique(sorted(list(DF[\"label_correlation\"]), reverse=True)):\n",
    "\n",
    "        def stats_for_lambda(lambda_):\n",
    "            df = (\n",
    "                DF[\n",
    "                    (DF[\"label_correlation\"] == l_corr)\n",
    "                    & (DF[\"indep\"] == \"conditional_hsic\")\n",
    "                    & (DF[\"lambda\"] == lambda_)\n",
    "                    & (DF[\"Problem.initial_lr\"] == lr)\n",
    "                ]\n",
    "                .sample(1)\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "            return statistics_for_series(df.iloc[0])\n",
    "\n",
    "        df_for_fig = DF[\n",
    "            (DF[\"label_correlation\"] == l_corr)\n",
    "            & (DF[\"Problem.initial_lr\"] == lr)\n",
    "            & (DF[\"generalization_error_model\"] == \"ensemble\")\n",
    "        ].copy()\n",
    "\n",
    "        fig = lib_plot.end_to_end_plot(\n",
    "            go.Figure(),\n",
    "            df_for_fig,\n",
    "            \"generalization_error\",\n",
    "            [\"generalization_error_model\", \"indep\"],\n",
    "            f\"MSAcc between per-digit accuracies for label correlation {l_corr}; learning rate {lr}\",\n",
    "        )\n",
    "\n",
    "        fig_diversity = lib_plot.end_to_end_plot(\n",
    "            go.Figure(),\n",
    "            df_for_fig,\n",
    "            \"train_diversity_loss\",\n",
    "            [\"indep\"],\n",
    "            f\"Train diversity loss for label correlation {l_corr}; learning rate {lr}\",\n",
    "        )\n",
    "        per_lambda_stats = html.Div(\n",
    "            [\n",
    "                dcc.Tabs(\n",
    "                    [\n",
    "                        dcc.Tab(\n",
    "                            label=f\"Lambda = {lambda_}\",\n",
    "                            children=stats_for_lambda(lambda_),\n",
    "                        )\n",
    "                        for lambda_ in sorted(np.unique(DF[\"lambda\"]))\n",
    "                    ]\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        tabs_for_outer.append(\n",
    "            dcc.Tab(\n",
    "                label=f\"label correlation {l_corr}\",\n",
    "                children=[\n",
    "                    dcc.Graph(figure=fig),\n",
    "                    dcc.Graph(figure=fig_diversity),\n",
    "                    per_lambda_stats,\n",
    "                ],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    top_level_tabs.append(\n",
    "        dcc.Tab(label=f\"learning rate {lr}\", children=[dcc.Tabs(tabs_for_outer)],)\n",
    "    )\n",
    "\n",
    "app = JupyterDash(__name__, external_stylesheets=external_stylesheets)\n",
    "app.layout = html.Div([dcc.Tabs(top_level_tabs)])\n",
    "app.run_server(mode=\"inline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_prediction_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_diversity_loss</th>\n",
       "      <th>test_combined_loss</th>\n",
       "      <th>test_ensemble_accuracy</th>\n",
       "      <th>train_prediction_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_diversity_loss</th>\n",
       "      <th>train_combined_loss</th>\n",
       "      <th>train_ensemble_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>BiasedMnistProblem.model_type</th>\n",
       "      <th>BiasedMnistProblem.background_noise_level</th>\n",
       "      <th>Problem.n_epochs</th>\n",
       "      <th>Problem.initial_lr</th>\n",
       "      <th>Problem.decrease_lr_at_epochs</th>\n",
       "      <th>Problem.n_models</th>\n",
       "      <th>get_weight_regularizer.strength</th>\n",
       "      <th>original_config</th>\n",
       "      <th>generalization_error</th>\n",
       "      <th>generalization_error_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.18410581350326538, 2.0631585121154785]</td>\n",
       "      <td>[0.944208025932312, 0.547517716884613]</td>\n",
       "      <td>1.109123</td>\n",
       "      <td>73.231110</td>\n",
       "      <td>0.806619</td>\n",
       "      <td>[0.0006089136586524546, 0.008913685567677021]</td>\n",
       "      <td>[0.9996841549873352, 0.9982629418373108]</td>\n",
       "      <td>0.006149</td>\n",
       "      <td>0.403069</td>\n",
       "      <td>0.999131</td>\n",
       "      <td>...</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[20, 40, 80]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>../data/3c2e4/biased_mnist/conditional_hsic/ml...</td>\n",
       "      <td>0.045813</td>\n",
       "      <td>network_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.18410581350326538, 2.0631585121154785]</td>\n",
       "      <td>[0.944208025932312, 0.547517716884613]</td>\n",
       "      <td>1.109123</td>\n",
       "      <td>73.231110</td>\n",
       "      <td>0.806619</td>\n",
       "      <td>[0.0006089136586524546, 0.008913685567677021]</td>\n",
       "      <td>[0.9996841549873352, 0.9982629418373108]</td>\n",
       "      <td>0.006149</td>\n",
       "      <td>0.403069</td>\n",
       "      <td>0.999131</td>\n",
       "      <td>...</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[20, 40, 80]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>../data/3c2e4/biased_mnist/conditional_hsic/ml...</td>\n",
       "      <td>0.900042</td>\n",
       "      <td>network_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.18410581350326538, 2.0631585121154785]</td>\n",
       "      <td>[0.944208025932312, 0.547517716884613]</td>\n",
       "      <td>1.109123</td>\n",
       "      <td>73.231110</td>\n",
       "      <td>0.806619</td>\n",
       "      <td>[0.0006089136586524546, 0.008913685567677021]</td>\n",
       "      <td>[0.9996841549873352, 0.9982629418373108]</td>\n",
       "      <td>0.006149</td>\n",
       "      <td>0.403069</td>\n",
       "      <td>0.999131</td>\n",
       "      <td>...</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[20, 40, 80]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>../data/3c2e4/biased_mnist/conditional_hsic/ml...</td>\n",
       "      <td>0.302390</td>\n",
       "      <td>ensemble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1.1909431219100952, 1.472009539604187]</td>\n",
       "      <td>[0.778723418712616, 0.5924350023269653]</td>\n",
       "      <td>1.323529</td>\n",
       "      <td>87.368805</td>\n",
       "      <td>0.698818</td>\n",
       "      <td>[0.00471786642447114, 0.006201746873557568]</td>\n",
       "      <td>[0.9992104172706604, 0.9984998106956482]</td>\n",
       "      <td>0.006343</td>\n",
       "      <td>0.416851</td>\n",
       "      <td>0.998658</td>\n",
       "      <td>...</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[20, 40, 80]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>../data/3c2e4/biased_mnist/conditional_hsic/ml...</td>\n",
       "      <td>0.342523</td>\n",
       "      <td>network_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1.1909431219100952, 1.472009539604187]</td>\n",
       "      <td>[0.778723418712616, 0.5924350023269653]</td>\n",
       "      <td>1.323529</td>\n",
       "      <td>87.368805</td>\n",
       "      <td>0.698818</td>\n",
       "      <td>[0.00471786642447114, 0.006201746873557568]</td>\n",
       "      <td>[0.9992104172706604, 0.9984998106956482]</td>\n",
       "      <td>0.006343</td>\n",
       "      <td>0.416851</td>\n",
       "      <td>0.998658</td>\n",
       "      <td>...</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[20, 40, 80]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>../data/3c2e4/biased_mnist/conditional_hsic/ml...</td>\n",
       "      <td>0.716972</td>\n",
       "      <td>network_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>[33.45603561401367, 9.348630905151367]</td>\n",
       "      <td>[0.9659574627876282, 0.9659574627876282]</td>\n",
       "      <td>0.913605</td>\n",
       "      <td>42.804668</td>\n",
       "      <td>0.969740</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>0.859562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1.00</td>\n",
       "      <td>[20, 40, 80]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>../data/3c2e4/biased_mnist/conditional_hsic/ml...</td>\n",
       "      <td>0.036766</td>\n",
       "      <td>network_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>[33.45603561401367, 9.348630905151367]</td>\n",
       "      <td>[0.9659574627876282, 0.9659574627876282]</td>\n",
       "      <td>0.913605</td>\n",
       "      <td>42.804668</td>\n",
       "      <td>0.969740</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>0.859562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1.00</td>\n",
       "      <td>[20, 40, 80]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>../data/3c2e4/biased_mnist/conditional_hsic/ml...</td>\n",
       "      <td>0.011122</td>\n",
       "      <td>ensemble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>[44.6565055847168, 100.33548736572266]</td>\n",
       "      <td>[0.9385342597961426, 0.9456264972686768]</td>\n",
       "      <td>0.853298</td>\n",
       "      <td>144.992004</td>\n",
       "      <td>0.938061</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>0.807168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1.00</td>\n",
       "      <td>[20, 40, 80]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>../data/3c2e4/biased_mnist/conditional_hsic/ml...</td>\n",
       "      <td>0.022644</td>\n",
       "      <td>network_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>[44.6565055847168, 100.33548736572266]</td>\n",
       "      <td>[0.9385342597961426, 0.9456264972686768]</td>\n",
       "      <td>0.853298</td>\n",
       "      <td>144.992004</td>\n",
       "      <td>0.938061</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>0.807168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1.00</td>\n",
       "      <td>[20, 40, 80]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>../data/3c2e4/biased_mnist/conditional_hsic/ml...</td>\n",
       "      <td>0.037955</td>\n",
       "      <td>network_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>[44.6565055847168, 100.33548736572266]</td>\n",
       "      <td>[0.9385342597961426, 0.9456264972686768]</td>\n",
       "      <td>0.853298</td>\n",
       "      <td>144.992004</td>\n",
       "      <td>0.938061</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>0.807168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1.00</td>\n",
       "      <td>[20, 40, 80]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>../data/3c2e4/biased_mnist/conditional_hsic/ml...</td>\n",
       "      <td>0.037433</td>\n",
       "      <td>ensemble</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2160 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           test_prediction_loss  \\\n",
       "0     [0.18410581350326538, 2.0631585121154785]   \n",
       "1     [0.18410581350326538, 2.0631585121154785]   \n",
       "2     [0.18410581350326538, 2.0631585121154785]   \n",
       "3       [1.1909431219100952, 1.472009539604187]   \n",
       "4       [1.1909431219100952, 1.472009539604187]   \n",
       "...                                         ...   \n",
       "2155     [33.45603561401367, 9.348630905151367]   \n",
       "2156     [33.45603561401367, 9.348630905151367]   \n",
       "2157     [44.6565055847168, 100.33548736572266]   \n",
       "2158     [44.6565055847168, 100.33548736572266]   \n",
       "2159     [44.6565055847168, 100.33548736572266]   \n",
       "\n",
       "                                 test_accuracy  test_diversity_loss  \\\n",
       "0       [0.944208025932312, 0.547517716884613]             1.109123   \n",
       "1       [0.944208025932312, 0.547517716884613]             1.109123   \n",
       "2       [0.944208025932312, 0.547517716884613]             1.109123   \n",
       "3      [0.778723418712616, 0.5924350023269653]             1.323529   \n",
       "4      [0.778723418712616, 0.5924350023269653]             1.323529   \n",
       "...                                        ...                  ...   \n",
       "2155  [0.9659574627876282, 0.9659574627876282]             0.913605   \n",
       "2156  [0.9659574627876282, 0.9659574627876282]             0.913605   \n",
       "2157  [0.9385342597961426, 0.9456264972686768]             0.853298   \n",
       "2158  [0.9385342597961426, 0.9456264972686768]             0.853298   \n",
       "2159  [0.9385342597961426, 0.9456264972686768]             0.853298   \n",
       "\n",
       "      test_combined_loss  test_ensemble_accuracy  \\\n",
       "0              73.231110                0.806619   \n",
       "1              73.231110                0.806619   \n",
       "2              73.231110                0.806619   \n",
       "3              87.368805                0.698818   \n",
       "4              87.368805                0.698818   \n",
       "...                  ...                     ...   \n",
       "2155           42.804668                0.969740   \n",
       "2156           42.804668                0.969740   \n",
       "2157          144.992004                0.938061   \n",
       "2158          144.992004                0.938061   \n",
       "2159          144.992004                0.938061   \n",
       "\n",
       "                              train_prediction_loss  \\\n",
       "0     [0.0006089136586524546, 0.008913685567677021]   \n",
       "1     [0.0006089136586524546, 0.008913685567677021]   \n",
       "2     [0.0006089136586524546, 0.008913685567677021]   \n",
       "3       [0.00471786642447114, 0.006201746873557568]   \n",
       "4       [0.00471786642447114, 0.006201746873557568]   \n",
       "...                                             ...   \n",
       "2155                                     [0.0, 0.0]   \n",
       "2156                                     [0.0, 0.0]   \n",
       "2157                                     [0.0, 0.0]   \n",
       "2158                                     [0.0, 0.0]   \n",
       "2159                                     [0.0, 0.0]   \n",
       "\n",
       "                                train_accuracy  train_diversity_loss  \\\n",
       "0     [0.9996841549873352, 0.9982629418373108]              0.006149   \n",
       "1     [0.9996841549873352, 0.9982629418373108]              0.006149   \n",
       "2     [0.9996841549873352, 0.9982629418373108]              0.006149   \n",
       "3     [0.9992104172706604, 0.9984998106956482]              0.006343   \n",
       "4     [0.9992104172706604, 0.9984998106956482]              0.006343   \n",
       "...                                        ...                   ...   \n",
       "2155                                [1.0, 1.0]              0.859562   \n",
       "2156                                [1.0, 1.0]              0.859562   \n",
       "2157                                [1.0, 1.0]              0.807168   \n",
       "2158                                [1.0, 1.0]              0.807168   \n",
       "2159                                [1.0, 1.0]              0.807168   \n",
       "\n",
       "      train_combined_loss  train_ensemble_accuracy  ...  \\\n",
       "0                0.403069                 0.999131  ...   \n",
       "1                0.403069                 0.999131  ...   \n",
       "2                0.403069                 0.999131  ...   \n",
       "3                0.416851                 0.998658  ...   \n",
       "4                0.416851                 0.998658  ...   \n",
       "...                   ...                      ...  ...   \n",
       "2155             0.000000                 1.000000  ...   \n",
       "2156             0.000000                 1.000000  ...   \n",
       "2157             0.000000                 1.000000  ...   \n",
       "2158             0.000000                 1.000000  ...   \n",
       "2159             0.000000                 1.000000  ...   \n",
       "\n",
       "     BiasedMnistProblem.model_type BiasedMnistProblem.background_noise_level  \\\n",
       "0                              mlp                                         0   \n",
       "1                              mlp                                         0   \n",
       "2                              mlp                                         0   \n",
       "3                              mlp                                         0   \n",
       "4                              mlp                                         0   \n",
       "...                            ...                                       ...   \n",
       "2155                           mlp                                         0   \n",
       "2156                           mlp                                         0   \n",
       "2157                           mlp                                         0   \n",
       "2158                           mlp                                         0   \n",
       "2159                           mlp                                         0   \n",
       "\n",
       "     Problem.n_epochs Problem.initial_lr  Problem.decrease_lr_at_epochs  \\\n",
       "0                 100               0.01                   [20, 40, 80]   \n",
       "1                 100               0.01                   [20, 40, 80]   \n",
       "2                 100               0.01                   [20, 40, 80]   \n",
       "3                 100               0.01                   [20, 40, 80]   \n",
       "4                 100               0.01                   [20, 40, 80]   \n",
       "...               ...                ...                            ...   \n",
       "2155              100               1.00                   [20, 40, 80]   \n",
       "2156              100               1.00                   [20, 40, 80]   \n",
       "2157              100               1.00                   [20, 40, 80]   \n",
       "2158              100               1.00                   [20, 40, 80]   \n",
       "2159              100               1.00                   [20, 40, 80]   \n",
       "\n",
       "      Problem.n_models get_weight_regularizer.strength  \\\n",
       "0                    2                            0.01   \n",
       "1                    2                            0.01   \n",
       "2                    2                            0.01   \n",
       "3                    2                            0.01   \n",
       "4                    2                            0.01   \n",
       "...                ...                             ...   \n",
       "2155                 2                            0.01   \n",
       "2156                 2                            0.01   \n",
       "2157                 2                            0.01   \n",
       "2158                 2                            0.01   \n",
       "2159                 2                            0.01   \n",
       "\n",
       "                                        original_config  generalization_error  \\\n",
       "0     ../data/3c2e4/biased_mnist/conditional_hsic/ml...              0.045813   \n",
       "1     ../data/3c2e4/biased_mnist/conditional_hsic/ml...              0.900042   \n",
       "2     ../data/3c2e4/biased_mnist/conditional_hsic/ml...              0.302390   \n",
       "3     ../data/3c2e4/biased_mnist/conditional_hsic/ml...              0.342523   \n",
       "4     ../data/3c2e4/biased_mnist/conditional_hsic/ml...              0.716972   \n",
       "...                                                 ...                   ...   \n",
       "2155  ../data/3c2e4/biased_mnist/conditional_hsic/ml...              0.036766   \n",
       "2156  ../data/3c2e4/biased_mnist/conditional_hsic/ml...              0.011122   \n",
       "2157  ../data/3c2e4/biased_mnist/conditional_hsic/ml...              0.022644   \n",
       "2158  ../data/3c2e4/biased_mnist/conditional_hsic/ml...              0.037955   \n",
       "2159  ../data/3c2e4/biased_mnist/conditional_hsic/ml...              0.037433   \n",
       "\n",
       "      generalization_error_model  \n",
       "0                      network_0  \n",
       "1                      network_1  \n",
       "2                       ensemble  \n",
       "3                      network_0  \n",
       "4                      network_1  \n",
       "...                          ...  \n",
       "2155                   network_1  \n",
       "2156                    ensemble  \n",
       "2157                   network_0  \n",
       "2158                   network_1  \n",
       "2159                    ensemble  \n",
       "\n",
       "[2160 rows x 27 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def visualize_weights(model: tf.keras.Model):\n",
    "    (feature_extractor, logistic) = model.layers[-2:]\n",
    "    [kernel, bias] = feature_extractor.get_weights()\n",
    "\n",
    "    n_hidden_neurons = kernel.shape[-1]\n",
    "\n",
    "    as_images = np.resize(kernel, (28, 28, 3, n_hidden_neurons))\n",
    "\n",
    "    f, axarr = plt.subplots(n_hidden_neurons, 3, figsize=(15, 15))\n",
    "\n",
    "    f.tight_layout()\n",
    "\n",
    "    for i in range(n_hidden_neurons):\n",
    "        for c in range(3):\n",
    "            for_neuron = as_images[:, :, c, i]\n",
    "\n",
    "            for_neuron = np.abs(for_neuron)\n",
    "\n",
    "            axarr[i, c].imshow(for_neuron, cmap=\"gray\")\n",
    "            axarr[i, c].axis(\"off\")\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.01, hspace=0.0001, right=10, left=9.3)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
