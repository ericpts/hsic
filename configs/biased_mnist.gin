main.experiment_name = 'biased_mnist'

# Parameters for BiasedMnistProblem:
# ==============================================================================
BiasedMnistScenario.background_noise_level = 50
BiasedMnistScenario.filter_for_digits = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
BiasedMnistScenario.training_data_label_correlation = 0.99

# Parameters for compute_combined_loss:
# ==============================================================================

# Parameters for diversity_loss:
# ==============================================================================
diversity_loss.independence_measure = 'cka'
diversity_loss.kernel = 'rbf'

# Parameters for get_weight_regularizer:
# ==============================================================================
get_weight_regularizer.strength = 0.0001

# Parameters for Problem:
# ==============================================================================
Problem.lambda_ = 1
Problem.batch_size = 256
Problem.decrease_lr_at_epochs = []
Problem.initial_lr = 0.001
Problem.n_epochs = 30
Problem.n_models = 2
Problem.optimizer = @tf.keras.optimizers.Adam
Problem.base_model = 'mlp'
Problem.scenario = @lib_biased_mnist.BiasedMnistScenario
tf.keras.optimizers.Adam.epsilon = 0.001
